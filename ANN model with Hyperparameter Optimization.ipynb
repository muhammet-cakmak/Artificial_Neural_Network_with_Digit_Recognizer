{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Introduction\n\nIn this workshop, I will show you how to build Artificial Neural Network(ANN) and how to tune its hyperparameters. I will use Digit Recognizer data set that is very famous among \"Kagglers\" who is specially interested in Neural Network. The data sets consist of the number of hand written digits that range from 0 to 9. The size og digits' photos er 28x28 which means each photo has 784 features(pixels). Also the data set consist of tran  and test sets. Train sets dimension is (42000x784) that means there are 42000 different photos in the train set while the test set dimension is (28000x784).\n\n**Metric:** I used \"accuracy metric\" as a metric to evaluate model performance.\n\n**Train set splitting:** I splitted the train set as %66 of train and 33% of dev set.\n\n<font color = 'blue'>\n Content:\n   \n   1. [Data Loading and Pre-processing](#1)\n   \n   2. [Building Model and Optimize Hyperparameters](#2)"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\n#pd.set_option(\"display.max_rows\", 999)\n#pd.set_option(\"display.max_columns\", 999)\n#pd.reset_option(\"display.max_rows\")\n#pd.reset_option(\"display.max_columns\")\n\nimport matplotlib.pyplot as plt\n\nimport tensorflow as tf\nfrom tensorflow import keras\nfrom tensorflow.keras import layers\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":1,"outputs":[{"output_type":"stream","text":"/kaggle/input/digit-recognizer/train.csv\n/kaggle/input/digit-recognizer/test.csv\n/kaggle/input/digit-recognizer/sample_submission.csv\n","name":"stdout"}]},{"metadata":{},"cell_type":"markdown","source":"<a id = '1'></a><br>\n## 1. Data Loading and Pre-processing"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Data loading\ntrain = pd.read_csv(\"/kaggle/input/digit-recognizer/train.csv\")\ntest = pd.read_csv(\"/kaggle/input/digit-recognizer/test.csv\")","execution_count":2,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Lets look at 5 rows of train set\ntrain.head()","execution_count":3,"outputs":[{"output_type":"execute_result","execution_count":3,"data":{"text/plain":"   label  pixel0  pixel1  pixel2  pixel3  pixel4  pixel5  pixel6  pixel7  \\\n0      1       0       0       0       0       0       0       0       0   \n1      0       0       0       0       0       0       0       0       0   \n2      1       0       0       0       0       0       0       0       0   \n3      4       0       0       0       0       0       0       0       0   \n4      0       0       0       0       0       0       0       0       0   \n\n   pixel8  ...  pixel774  pixel775  pixel776  pixel777  pixel778  pixel779  \\\n0       0  ...         0         0         0         0         0         0   \n1       0  ...         0         0         0         0         0         0   \n2       0  ...         0         0         0         0         0         0   \n3       0  ...         0         0         0         0         0         0   \n4       0  ...         0         0         0         0         0         0   \n\n   pixel780  pixel781  pixel782  pixel783  \n0         0         0         0         0  \n1         0         0         0         0  \n2         0         0         0         0  \n3         0         0         0         0  \n4         0         0         0         0  \n\n[5 rows x 785 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>label</th>\n      <th>pixel0</th>\n      <th>pixel1</th>\n      <th>pixel2</th>\n      <th>pixel3</th>\n      <th>pixel4</th>\n      <th>pixel5</th>\n      <th>pixel6</th>\n      <th>pixel7</th>\n      <th>pixel8</th>\n      <th>...</th>\n      <th>pixel774</th>\n      <th>pixel775</th>\n      <th>pixel776</th>\n      <th>pixel777</th>\n      <th>pixel778</th>\n      <th>pixel779</th>\n      <th>pixel780</th>\n      <th>pixel781</th>\n      <th>pixel782</th>\n      <th>pixel783</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>4</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows Ã— 785 columns</p>\n</div>"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Lets look at 5 rows of test set\ntest.head()","execution_count":4,"outputs":[{"output_type":"execute_result","execution_count":4,"data":{"text/plain":"   pixel0  pixel1  pixel2  pixel3  pixel4  pixel5  pixel6  pixel7  pixel8  \\\n0       0       0       0       0       0       0       0       0       0   \n1       0       0       0       0       0       0       0       0       0   \n2       0       0       0       0       0       0       0       0       0   \n3       0       0       0       0       0       0       0       0       0   \n4       0       0       0       0       0       0       0       0       0   \n\n   pixel9  ...  pixel774  pixel775  pixel776  pixel777  pixel778  pixel779  \\\n0       0  ...         0         0         0         0         0         0   \n1       0  ...         0         0         0         0         0         0   \n2       0  ...         0         0         0         0         0         0   \n3       0  ...         0         0         0         0         0         0   \n4       0  ...         0         0         0         0         0         0   \n\n   pixel780  pixel781  pixel782  pixel783  \n0         0         0         0         0  \n1         0         0         0         0  \n2         0         0         0         0  \n3         0         0         0         0  \n4         0         0         0         0  \n\n[5 rows x 784 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>pixel0</th>\n      <th>pixel1</th>\n      <th>pixel2</th>\n      <th>pixel3</th>\n      <th>pixel4</th>\n      <th>pixel5</th>\n      <th>pixel6</th>\n      <th>pixel7</th>\n      <th>pixel8</th>\n      <th>pixel9</th>\n      <th>...</th>\n      <th>pixel774</th>\n      <th>pixel775</th>\n      <th>pixel776</th>\n      <th>pixel777</th>\n      <th>pixel778</th>\n      <th>pixel779</th>\n      <th>pixel780</th>\n      <th>pixel781</th>\n      <th>pixel782</th>\n      <th>pixel783</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows Ã— 784 columns</p>\n</div>"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Target variable\ny = train.pop(\"label\")\n","execution_count":5,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Lets look at 5 rows of the target variable\ny.head()","execution_count":6,"outputs":[{"output_type":"execute_result","execution_count":6,"data":{"text/plain":"0    1\n1    0\n2    1\n3    4\n4    0\nName: label, dtype: int64"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Unique values and their frequiencies in the target variable\ny.value_counts()","execution_count":7,"outputs":[{"output_type":"execute_result","execution_count":7,"data":{"text/plain":"1    4684\n7    4401\n3    4351\n9    4188\n2    4177\n6    4137\n0    4132\n4    4072\n8    4063\n5    3795\nName: label, dtype: int64"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"# train set has 784 feature(pixels) and 42000 photos, test set has 784 feature and 28000 photos.  \ntrain.shape,y.shape,test.shape","execution_count":8,"outputs":[{"output_type":"execute_result","execution_count":8,"data":{"text/plain":"((42000, 784), (42000,), (28000, 784))"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Gets info quickly about data set\ntest.info()","execution_count":9,"outputs":[{"output_type":"stream","text":"<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 28000 entries, 0 to 27999\nColumns: 784 entries, pixel0 to pixel783\ndtypes: int64(784)\nmemory usage: 167.5 MB\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Gets info quickly about data set\ntrain.info()","execution_count":10,"outputs":[{"output_type":"stream","text":"<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 42000 entries, 0 to 41999\nColumns: 784 entries, pixel0 to pixel783\ndtypes: int64(784)\nmemory usage: 251.2 MB\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Type of the values in y variable\ny.dtype","execution_count":11,"outputs":[{"output_type":"execute_result","execution_count":11,"data":{"text/plain":"dtype('int64')"},"metadata":{}}]},{"metadata":{},"cell_type":"markdown","source":"**Note: Keras accepts data with type of float32, and normilizing pixels by dividing 255 will sharply increase the speed of the ANN.**"},{"metadata":{"trusted":true},"cell_type":"code","source":"# scale the input values to type float32 and (normalize) the input values within the interval [0, 1]\n\ntrain = train.astype('float32')/255\ntest = test.astype('float32')/255\ny = y.astype('float32')\n\n","execution_count":12,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Converting pandas Dataframe to numpy array\n\"\"\"\nKeras models accept three types of inputs:\n\nNumPy arrays, just like Scikit-Learn and many other Python-based libraries. This is a good option if your data fits in memory.\n\nTensorFlow Dataset objects. This is a high-performance option that is more suitable for datasets that do not fit in memory and that are streamed from disk or from a distributed filesystem.\n\nPython generators that yield batches of data (such as custom subclasses of the keras.utils.Sequence class).\n\"\"\"\ntrain = pd.DataFrame.to_numpy(train)\ntest = pd.DataFrame.to_numpy(test)","execution_count":13,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Splitting training set into train and dev set \nfrom sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(train, y, test_size=0.33, random_state=42)","execution_count":14,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Y variable has 10 different classes. Therefore we need to represent each values in y as vector. \n# This converst for example  1 to [0., 1., 0., 0., 0., 0., 0., 0., 0., 0.] vector. \n\"\"\"\n# label encoding to y variable\nfrom keras.utils import to_categorical\ny = to_categorical(y, num_classes=10)\n\"\"\"\ny_onehot = tf.one_hot(y, depth=10)\ny_onehot_train = tf.one_hot(y_train, depth=10)\ny_onehot_test = tf.one_hot(y_test, depth=10)","execution_count":15,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a id = '2'></a><br>\n##  2. Building Model and Optimize Hyperparameters"},{"metadata":{"trusted":true},"cell_type":"code","source":"from tensorflow import keras\n# Importing libraries\nfrom keras.models import Sequential              # creates sequential model\nfrom keras.layers.core import Dense, Activation # creates layers and calls activation functions\nfrom tensorflow.keras.layers import (\n    Dense,\n    Dropout,\n    Flatten\n)\n\nfrom kerastuner import HyperModel  # It helps to tune hyperparameters.","execution_count":47,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\"\"\"\nHyperparameter tuning is heart of  ANN model and it directly affects the performance of the model. We can tune hyperparameters such as:\n\nLearning Rate : It determines how quick the model will learn. It should be selected carefully. If it is small, the model speed will be very slow which means the derivative \nof loss function goes to its minimum point very slowly. If it is very high, the derivative of the loss fucntion cannot reach to its global minimum point. \nTherefore I preffered to choose its values as 1e-2, 1e-3, 1e-4.\n\nThe number of nodes: Nodes are points of the Layers on ANN. We need to optimize them and it is very general that they can be choosen as 32,64,128,256 and 512. \n\nThe number of layer: It determines the complexity of the ANN model like the nodes. If you choose very high number, it can result in \"BÄ°AS\". If you choose very small like 2,\nit may not be good to solve complex and non-linear problems. We use dense function to create layers.\n\nActivation function: Normally ANN is the linear method (Z=W*X+b), but we use activation function to make ANN non-linear. The most famous activation functions are relu and \ntanh for layers. If you use binary classification, you need to use \"sigmoid\" funcion. If you classify more than 2 classes, you need to use \"softmax\" function.\n\nL2 Regularization: Regularization is used to reduce \"VARÄ°ANCE\" problem. One of the regularization techniques is L2 that is added to loss function to punish the weights.\nBy doing this weights getting closer to zero which reduces the model complexity.\n\nDropout: It is another regularization techniues. It is based on to close some of nodes randomly in determined layers. It uses \"BERNOULLÄ° PROBABLÄ°TY\" to determine which nodes \nis getting closed. It is very effective like L2 regularization. It is very commen to use both L2 and Dropout regularization.\n\nAdam optimazation: There are different optimazation methods like \"momentum\" and \"RMSProp\" to speed the model and increase the model performance. \"ADAM\" optimization technique\nuses noth momentum and RMSProp(Root Mean Square Prop)\n\nBatch-size : It is based on to divide data into small datasets and train them. It increase the performance beside speeding model training time. Exponentially weighted avarages \nstatistical technique is used to calculate avarage loss on this technique. \n\n\n\n\n\"\"\"\nclass AnnHyperModel(HyperModel): \n    def __init__(self, input_shape):\n        self.input_shape = input_shape\n        \n        \n    def build(self, hp):\n        model = Sequential()\n        model.add(\n            layers.Dense(\n                units=hp.Int('units', 8, 64, 4, default=8), \n                activation=hp.Choice(\n                    'dense_activation', \n                    values=['relu', 'tanh', 'elu'],\n                    default='relu'), \n                activity_regularizer=tf.keras.regularizers.l2(0.001),\n                input_shape=input_shape) )\n        \n        model.add( \n            layers.Dense(\n            units=hp.Int('units', 8, 64, 4, default=16), \n            activation=hp.Choice(\n                'dense_activation', \n                values=['relu', 'tanh', 'elu'], \n                default='relu')))\n\n        model.add( \n            layers.Dropout(\n                hp.Float( \n                    'dropout',\n                    min_value=0.0, \n                    max_value=0.1, \n                    default=0.005, \n                    step=0.01)))\n        \n    \n        model.add(layers.Dense(10,activation = \"softmax\"))\n        \n        model.compile(\n            optimizer=keras.optimizers.Adam(\n            hp.Choice('learning_rate',\n                      values=[1e-2, 1e-3, 1e-4]))\n            ,loss='mse',\n            metrics=['accuracy'] )\n\n        return model","execution_count":22,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"input_shape = (X_train.shape[1],)\nhypermodel = AnnHyperModel(input_shape)","execution_count":23,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from kerastuner.tuners import RandomSearch","execution_count":24,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\ntuner_rs = RandomSearch( hypermodel,\n                        objective='val_accuracy', \n                        seed=42, \n                        max_trials=10, \n                        executions_per_trial=2)","execution_count":28,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# You can print a summary of the search space\ntuner_rs.search_space_summary()","execution_count":30,"outputs":[{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"<span style=\"color:#4527A0\"><h1 style=\"font-size:18px\">Search space summary</h1></span>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"<span style=\"color:cyan\"> |-Default search space size: 3</span>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"<span style=\"color:#7E57C2\"><h2 style=\"font-size:16px\">units (Int)</h2></span>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"<span style=\"color:cyan\"> |-default: 8</span>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"<span style=\"color:blue\"> |-max_value: 64</span>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"<span style=\"color:cyan\"> |-min_value: 8</span>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"<span style=\"color:blue\"> |-sampling: None</span>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"<span style=\"color:cyan\"> |-step: 4</span>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"<span style=\"color:#7E57C2\"><h2 style=\"font-size:16px\">dense_activation (Choice)</h2></span>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"<span style=\"color:cyan\"> |-default: relu</span>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"<span style=\"color:blue\"> |-ordered: False</span>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"<span style=\"color:cyan\"> |-values: ['relu', 'tanh', 'elu']</span>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"<span style=\"color:#7E57C2\"><h2 style=\"font-size:16px\">dropout (Float)</h2></span>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"<span style=\"color:cyan\"> |-default: 0.005</span>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"<span style=\"color:blue\"> |-max_value: 0.1</span>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"<span style=\"color:cyan\"> |-min_value: 0.0</span>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"<span style=\"color:blue\"> |-sampling: None</span>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"<span style=\"color:cyan\"> |-step: 0.01</span>"},"metadata":{}}]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"# fit the model to find best model\ntuner_rs.search(X_train, y_onehot_train, epochs=10, validation_data=(X_test, y_onehot_test), verbose=2)","execution_count":31,"outputs":[{"output_type":"stream","text":"Epoch 1/10\n880/880 - 2s - loss: 0.0424 - accuracy: 0.7544 - val_loss: 0.0417 - val_accuracy: 0.7577\nEpoch 2/10\n880/880 - 2s - loss: 0.0415 - accuracy: 0.7692 - val_loss: 0.0399 - val_accuracy: 0.7879\nEpoch 3/10\n880/880 - 2s - loss: 0.0426 - accuracy: 0.7603 - val_loss: 0.0419 - val_accuracy: 0.7556\nEpoch 4/10\n880/880 - 2s - loss: 0.0464 - accuracy: 0.7361 - val_loss: 0.0421 - val_accuracy: 0.7380\nEpoch 5/10\n880/880 - 2s - loss: 0.0468 - accuracy: 0.7364 - val_loss: 0.0462 - val_accuracy: 0.7218\nEpoch 6/10\n880/880 - 2s - loss: 0.0489 - accuracy: 0.7177 - val_loss: 0.0586 - val_accuracy: 0.5741\nEpoch 7/10\n880/880 - 2s - loss: 0.0500 - accuracy: 0.7119 - val_loss: 0.0507 - val_accuracy: 0.7120\nEpoch 8/10\n880/880 - 2s - loss: 0.0521 - accuracy: 0.6922 - val_loss: 0.0491 - val_accuracy: 0.7290\nEpoch 9/10\n880/880 - 2s - loss: 0.0502 - accuracy: 0.7088 - val_loss: 0.0552 - val_accuracy: 0.7158\nEpoch 10/10\n880/880 - 2s - loss: 0.0512 - accuracy: 0.7068 - val_loss: 0.0625 - val_accuracy: 0.7287\nEpoch 1/10\n880/880 - 2s - loss: 0.0359 - accuracy: 0.8154 - val_loss: 0.0333 - val_accuracy: 0.8180\nEpoch 2/10\n880/880 - 2s - loss: 0.0363 - accuracy: 0.8289 - val_loss: 0.0412 - val_accuracy: 0.8123\nEpoch 3/10\n880/880 - 2s - loss: 0.0379 - accuracy: 0.8234 - val_loss: 0.0425 - val_accuracy: 0.7128\nEpoch 4/10\n880/880 - 2s - loss: 0.0412 - accuracy: 0.7913 - val_loss: 0.0418 - val_accuracy: 0.7307\nEpoch 5/10\n880/880 - 2s - loss: 0.0400 - accuracy: 0.7961 - val_loss: 0.0393 - val_accuracy: 0.7867\nEpoch 6/10\n880/880 - 2s - loss: 0.0417 - accuracy: 0.7904 - val_loss: 0.0398 - val_accuracy: 0.7692\nEpoch 7/10\n880/880 - 2s - loss: 0.0429 - accuracy: 0.7708 - val_loss: 0.0548 - val_accuracy: 0.8013\nEpoch 8/10\n880/880 - 2s - loss: 0.0449 - accuracy: 0.7654 - val_loss: 0.0473 - val_accuracy: 0.7994\nEpoch 9/10\n880/880 - 2s - loss: 0.0471 - accuracy: 0.7390 - val_loss: 0.0454 - val_accuracy: 0.7291\nEpoch 10/10\n880/880 - 2s - loss: 0.0460 - accuracy: 0.7564 - val_loss: 0.0444 - val_accuracy: 0.7445\n","name":"stdout"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"<span style=\"color:#4527A0\"><h1 style=\"font-size:18px\">Trial complete</h1></span>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"<span style=\"color:#4527A0\"><h1 style=\"font-size:18px\">Trial summary</h1></span>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"<span style=\"color:cyan\"> |-Trial ID: a33ebe983aafed46f619d3195aa39395</span>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"<span style=\"color:cyan\"> |-Score: 0.8029581606388092</span>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"<span style=\"color:cyan\"> |-Best step: 0</span>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"<span style=\"color:#7E57C2\"><h2 style=\"font-size:16px\">Hyperparameters:</h2></span>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"<span style=\"color:cyan\"> |-dense_activation: relu</span>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"<span style=\"color:blue\"> |-dropout: 0.1</span>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"<span style=\"color:cyan\"> |-learning_rate: 0.01</span>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"<span style=\"color:blue\"> |-units: 60</span>"},"metadata":{}},{"output_type":"stream","text":"Epoch 1/10\n880/880 - 2s - loss: 0.0347 - accuracy: 0.8311 - val_loss: 0.0222 - val_accuracy: 0.8988\nEpoch 2/10\n880/880 - 2s - loss: 0.0207 - accuracy: 0.9037 - val_loss: 0.0190 - val_accuracy: 0.9105\nEpoch 3/10\n880/880 - 2s - loss: 0.0181 - accuracy: 0.9150 - val_loss: 0.0177 - val_accuracy: 0.9139\nEpoch 4/10\n880/880 - 2s - loss: 0.0168 - accuracy: 0.9221 - val_loss: 0.0172 - val_accuracy: 0.9154\nEpoch 5/10\n880/880 - 2s - loss: 0.0159 - accuracy: 0.9264 - val_loss: 0.0161 - val_accuracy: 0.9234\nEpoch 6/10\n880/880 - 2s - loss: 0.0152 - accuracy: 0.9297 - val_loss: 0.0162 - val_accuracy: 0.9203\nEpoch 7/10\n880/880 - 2s - loss: 0.0147 - accuracy: 0.9326 - val_loss: 0.0160 - val_accuracy: 0.9232\nEpoch 8/10\n880/880 - 2s - loss: 0.0143 - accuracy: 0.9350 - val_loss: 0.0158 - val_accuracy: 0.9234\nEpoch 9/10\n880/880 - 2s - loss: 0.0139 - accuracy: 0.9380 - val_loss: 0.0158 - val_accuracy: 0.9236\nEpoch 10/10\n880/880 - 2s - loss: 0.0137 - accuracy: 0.9393 - val_loss: 0.0155 - val_accuracy: 0.9255\nEpoch 1/10\n880/880 - 2s - loss: 0.0365 - accuracy: 0.8195 - val_loss: 0.0227 - val_accuracy: 0.8960\nEpoch 2/10\n880/880 - 2s - loss: 0.0210 - accuracy: 0.9026 - val_loss: 0.0193 - val_accuracy: 0.9096\nEpoch 3/10\n880/880 - 2s - loss: 0.0185 - accuracy: 0.9127 - val_loss: 0.0194 - val_accuracy: 0.9053\nEpoch 4/10\n880/880 - 2s - loss: 0.0170 - accuracy: 0.9200 - val_loss: 0.0177 - val_accuracy: 0.9132\nEpoch 5/10\n880/880 - 2s - loss: 0.0163 - accuracy: 0.9236 - val_loss: 0.0162 - val_accuracy: 0.9208\nEpoch 6/10\n880/880 - 2s - loss: 0.0156 - accuracy: 0.9273 - val_loss: 0.0170 - val_accuracy: 0.9166\nEpoch 7/10\n880/880 - 2s - loss: 0.0148 - accuracy: 0.9319 - val_loss: 0.0158 - val_accuracy: 0.9216\nEpoch 8/10\n880/880 - 2s - loss: 0.0143 - accuracy: 0.9353 - val_loss: 0.0157 - val_accuracy: 0.9245\nEpoch 9/10\n880/880 - 2s - loss: 0.0141 - accuracy: 0.9369 - val_loss: 0.0167 - val_accuracy: 0.9157\nEpoch 10/10\n880/880 - 2s - loss: 0.0138 - accuracy: 0.9377 - val_loss: 0.0159 - val_accuracy: 0.9211\n","name":"stdout"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"<span style=\"color:#4527A0\"><h1 style=\"font-size:18px\">Trial complete</h1></span>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"<span style=\"color:#4527A0\"><h1 style=\"font-size:18px\">Trial summary</h1></span>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"<span style=\"color:cyan\"> |-Trial ID: ec45aff5c1b56c12ff39bdc9701c5d38</span>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"<span style=\"color:cyan\"> |-Score: 0.9250360727310181</span>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"<span style=\"color:cyan\"> |-Best step: 0</span>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"<span style=\"color:#7E57C2\"><h2 style=\"font-size:16px\">Hyperparameters:</h2></span>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"<span style=\"color:cyan\"> |-dense_activation: elu</span>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"<span style=\"color:blue\"> |-dropout: 0.02</span>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"<span style=\"color:cyan\"> |-learning_rate: 0.001</span>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"<span style=\"color:blue\"> |-units: 12</span>"},"metadata":{}},{"output_type":"stream","text":"Epoch 1/10\n880/880 - 2s - loss: 0.0279 - accuracy: 0.8742 - val_loss: 0.0205 - val_accuracy: 0.9123\nEpoch 2/10\n880/880 - 2s - loss: 0.0193 - accuracy: 0.9163 - val_loss: 0.0195 - val_accuracy: 0.9115\nEpoch 3/10\n880/880 - 2s - loss: 0.0175 - accuracy: 0.9256 - val_loss: 0.0193 - val_accuracy: 0.9096\nEpoch 4/10\n880/880 - 2s - loss: 0.0164 - accuracy: 0.9314 - val_loss: 0.0169 - val_accuracy: 0.9271\nEpoch 5/10\n880/880 - 2s - loss: 0.0155 - accuracy: 0.9372 - val_loss: 0.0181 - val_accuracy: 0.9179\nEpoch 6/10\n880/880 - 2s - loss: 0.0149 - accuracy: 0.9403 - val_loss: 0.0166 - val_accuracy: 0.9300\nEpoch 7/10\n880/880 - 2s - loss: 0.0145 - accuracy: 0.9432 - val_loss: 0.0158 - val_accuracy: 0.9338\nEpoch 8/10\n880/880 - 2s - loss: 0.0141 - accuracy: 0.9464 - val_loss: 0.0161 - val_accuracy: 0.9307\nEpoch 9/10\n880/880 - 2s - loss: 0.0139 - accuracy: 0.9468 - val_loss: 0.0154 - val_accuracy: 0.9349\nEpoch 10/10\n880/880 - 2s - loss: 0.0135 - accuracy: 0.9494 - val_loss: 0.0164 - val_accuracy: 0.9311\nEpoch 1/10\n880/880 - 2s - loss: 0.0277 - accuracy: 0.8743 - val_loss: 0.0205 - val_accuracy: 0.9083\nEpoch 2/10\n880/880 - 2s - loss: 0.0192 - accuracy: 0.9163 - val_loss: 0.0195 - val_accuracy: 0.9123\nEpoch 3/10\n880/880 - 2s - loss: 0.0173 - accuracy: 0.9271 - val_loss: 0.0181 - val_accuracy: 0.9180\nEpoch 4/10\n880/880 - 2s - loss: 0.0162 - accuracy: 0.9334 - val_loss: 0.0174 - val_accuracy: 0.9234\nEpoch 5/10\n880/880 - 2s - loss: 0.0156 - accuracy: 0.9372 - val_loss: 0.0173 - val_accuracy: 0.9233\nEpoch 6/10\n880/880 - 2s - loss: 0.0149 - accuracy: 0.9408 - val_loss: 0.0164 - val_accuracy: 0.9300\nEpoch 7/10\n880/880 - 2s - loss: 0.0146 - accuracy: 0.9424 - val_loss: 0.0171 - val_accuracy: 0.9255\nEpoch 8/10\n880/880 - 2s - loss: 0.0139 - accuracy: 0.9458 - val_loss: 0.0160 - val_accuracy: 0.9335\nEpoch 9/10\n880/880 - 3s - loss: 0.0133 - accuracy: 0.9502 - val_loss: 0.0166 - val_accuracy: 0.9281\nEpoch 10/10\n880/880 - 3s - loss: 0.0132 - accuracy: 0.9509 - val_loss: 0.0163 - val_accuracy: 0.9301\n","name":"stdout"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"<span style=\"color:#4527A0\"><h1 style=\"font-size:18px\">Trial complete</h1></span>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"<span style=\"color:#4527A0\"><h1 style=\"font-size:18px\">Trial summary</h1></span>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"<span style=\"color:cyan\"> |-Trial ID: 66c4cc739f4b535e45ca98271390dd20</span>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"<span style=\"color:cyan\"> |-Score: 0.9342351853847504</span>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"<span style=\"color:cyan\"> |-Best step: 0</span>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"<span style=\"color:#7E57C2\"><h2 style=\"font-size:16px\">Hyperparameters:</h2></span>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"<span style=\"color:cyan\"> |-dense_activation: elu</span>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"<span style=\"color:blue\"> |-dropout: 0.04</span>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"<span style=\"color:cyan\"> |-learning_rate: 0.001</span>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"<span style=\"color:blue\"> |-units: 36</span>"},"metadata":{}},{"output_type":"stream","text":"Epoch 1/10\n880/880 - 3s - loss: 0.0693 - accuracy: 0.5644 - val_loss: 0.0467 - val_accuracy: 0.7851\nEpoch 2/10\n880/880 - 3s - loss: 0.0386 - accuracy: 0.8245 - val_loss: 0.0317 - val_accuracy: 0.8769\nEpoch 3/10\n880/880 - 3s - loss: 0.0276 - accuracy: 0.8964 - val_loss: 0.0243 - val_accuracy: 0.9056\nEpoch 4/10\n880/880 - 2s - loss: 0.0222 - accuracy: 0.9149 - val_loss: 0.0206 - val_accuracy: 0.9182\nEpoch 5/10\n880/880 - 2s - loss: 0.0191 - accuracy: 0.9246 - val_loss: 0.0183 - val_accuracy: 0.9258\nEpoch 6/10\n880/880 - 2s - loss: 0.0170 - accuracy: 0.9329 - val_loss: 0.0167 - val_accuracy: 0.9287\nEpoch 7/10\n880/880 - 2s - loss: 0.0154 - accuracy: 0.9390 - val_loss: 0.0154 - val_accuracy: 0.9339\nEpoch 8/10\n880/880 - 2s - loss: 0.0141 - accuracy: 0.9429 - val_loss: 0.0145 - val_accuracy: 0.9368\nEpoch 9/10\n880/880 - 2s - loss: 0.0130 - accuracy: 0.9480 - val_loss: 0.0136 - val_accuracy: 0.9389\nEpoch 10/10\n880/880 - 2s - loss: 0.0122 - accuracy: 0.9503 - val_loss: 0.0129 - val_accuracy: 0.9417\nEpoch 1/10\n880/880 - 2s - loss: 0.0709 - accuracy: 0.5274 - val_loss: 0.0478 - val_accuracy: 0.7794\nEpoch 2/10\n880/880 - 2s - loss: 0.0382 - accuracy: 0.8373 - val_loss: 0.0303 - val_accuracy: 0.8923\nEpoch 3/10\n880/880 - 2s - loss: 0.0267 - accuracy: 0.9032 - val_loss: 0.0238 - val_accuracy: 0.9105\nEpoch 4/10\n880/880 - 2s - loss: 0.0218 - accuracy: 0.9188 - val_loss: 0.0204 - val_accuracy: 0.9185\nEpoch 5/10\n880/880 - 2s - loss: 0.0189 - accuracy: 0.9270 - val_loss: 0.0183 - val_accuracy: 0.9245\nEpoch 6/10\n880/880 - 2s - loss: 0.0169 - accuracy: 0.9328 - val_loss: 0.0169 - val_accuracy: 0.9294\nEpoch 7/10\n880/880 - 2s - loss: 0.0154 - accuracy: 0.9378 - val_loss: 0.0158 - val_accuracy: 0.9312\nEpoch 8/10\n880/880 - 2s - loss: 0.0142 - accuracy: 0.9417 - val_loss: 0.0148 - val_accuracy: 0.9339\nEpoch 9/10\n880/880 - 2s - loss: 0.0133 - accuracy: 0.9458 - val_loss: 0.0142 - val_accuracy: 0.9360\nEpoch 10/10\n880/880 - 2s - loss: 0.0124 - accuracy: 0.9495 - val_loss: 0.0134 - val_accuracy: 0.9374\n","name":"stdout"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"<span style=\"color:#4527A0\"><h1 style=\"font-size:18px\">Trial complete</h1></span>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"<span style=\"color:#4527A0\"><h1 style=\"font-size:18px\">Trial summary</h1></span>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"<span style=\"color:cyan\"> |-Trial ID: 1548a000fcfbb362b70bc43927095b63</span>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"<span style=\"color:cyan\"> |-Score: 0.9395743012428284</span>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"<span style=\"color:cyan\"> |-Best step: 0</span>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"<span style=\"color:#7E57C2\"><h2 style=\"font-size:16px\">Hyperparameters:</h2></span>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"<span style=\"color:cyan\"> |-dense_activation: relu</span>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"<span style=\"color:blue\"> |-dropout: 0.01</span>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"<span style=\"color:cyan\"> |-learning_rate: 0.0001</span>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"<span style=\"color:blue\"> |-units: 32</span>"},"metadata":{}},{"output_type":"stream","text":"Epoch 1/10\n880/880 - 2s - loss: 0.0400 - accuracy: 0.7439 - val_loss: 0.0426 - val_accuracy: 0.7146\nEpoch 2/10\n880/880 - 2s - loss: 0.0406 - accuracy: 0.7531 - val_loss: 0.0422 - val_accuracy: 0.7401\nEpoch 3/10\n880/880 - 2s - loss: 0.0437 - accuracy: 0.7372 - val_loss: 0.0505 - val_accuracy: 0.7257\nEpoch 4/10\n880/880 - 2s - loss: 0.0464 - accuracy: 0.7335 - val_loss: 0.0439 - val_accuracy: 0.7535\nEpoch 5/10\n880/880 - 2s - loss: 0.0462 - accuracy: 0.7135 - val_loss: 0.0484 - val_accuracy: 0.7408\nEpoch 6/10\n880/880 - 2s - loss: 0.0489 - accuracy: 0.7135 - val_loss: 0.0543 - val_accuracy: 0.7405\nEpoch 7/10\n880/880 - 2s - loss: 0.0509 - accuracy: 0.6920 - val_loss: 0.0514 - val_accuracy: 0.6728\nEpoch 8/10\n880/880 - 2s - loss: 0.0519 - accuracy: 0.6846 - val_loss: 0.0522 - val_accuracy: 0.7012\nEpoch 9/10\n880/880 - 2s - loss: 0.0522 - accuracy: 0.6746 - val_loss: 0.0499 - val_accuracy: 0.6777\nEpoch 10/10\n880/880 - 2s - loss: 0.0519 - accuracy: 0.6801 - val_loss: 0.0573 - val_accuracy: 0.6035\nEpoch 1/10\n880/880 - 2s - loss: 0.0397 - accuracy: 0.7763 - val_loss: 0.0323 - val_accuracy: 0.8291\nEpoch 2/10\n880/880 - 2s - loss: 0.0372 - accuracy: 0.8178 - val_loss: 0.0402 - val_accuracy: 0.7560\nEpoch 3/10\n880/880 - 2s - loss: 0.0393 - accuracy: 0.8115 - val_loss: 0.0405 - val_accuracy: 0.8167\nEpoch 4/10\n880/880 - 2s - loss: 0.0427 - accuracy: 0.7916 - val_loss: 0.0481 - val_accuracy: 0.7729\nEpoch 5/10\n880/880 - 2s - loss: 0.0438 - accuracy: 0.7703 - val_loss: 0.0415 - val_accuracy: 0.7696\nEpoch 6/10\n880/880 - 2s - loss: 0.0439 - accuracy: 0.7850 - val_loss: 0.0444 - val_accuracy: 0.7790\nEpoch 7/10\n880/880 - 2s - loss: 0.0458 - accuracy: 0.7651 - val_loss: 0.0450 - val_accuracy: 0.7733\nEpoch 8/10\n880/880 - 2s - loss: 0.0451 - accuracy: 0.7563 - val_loss: 0.0436 - val_accuracy: 0.7446\nEpoch 9/10\n880/880 - 2s - loss: 0.0490 - accuracy: 0.7381 - val_loss: 0.0449 - val_accuracy: 0.7312\nEpoch 10/10\n880/880 - 2s - loss: 0.0489 - accuracy: 0.7291 - val_loss: 0.0547 - val_accuracy: 0.7513\n","name":"stdout"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"<span style=\"color:#4527A0\"><h1 style=\"font-size:18px\">Trial complete</h1></span>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"<span style=\"color:#4527A0\"><h1 style=\"font-size:18px\">Trial summary</h1></span>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"<span style=\"color:cyan\"> |-Trial ID: da8370ab061f7491d2366c78c852b6a5</span>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"<span style=\"color:cyan\"> |-Score: 0.7913059294223785</span>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"<span style=\"color:cyan\"> |-Best step: 0</span>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"<span style=\"color:#7E57C2\"><h2 style=\"font-size:16px\">Hyperparameters:</h2></span>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"<span style=\"color:cyan\"> |-dense_activation: relu</span>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"<span style=\"color:blue\"> |-dropout: 0.03</span>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"<span style=\"color:cyan\"> |-learning_rate: 0.01</span>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"<span style=\"color:blue\"> |-units: 48</span>"},"metadata":{}},{"output_type":"stream","text":"Epoch 1/10\n880/880 - 2s - loss: 0.0303 - accuracy: 0.8536 - val_loss: 0.0205 - val_accuracy: 0.9060\nEpoch 2/10\n880/880 - 2s - loss: 0.0193 - accuracy: 0.9135 - val_loss: 0.0208 - val_accuracy: 0.9004\nEpoch 3/10\n880/880 - 2s - loss: 0.0174 - accuracy: 0.9233 - val_loss: 0.0177 - val_accuracy: 0.9198\nEpoch 4/10\n880/880 - 2s - loss: 0.0161 - accuracy: 0.9313 - val_loss: 0.0166 - val_accuracy: 0.9257\nEpoch 5/10\n880/880 - 2s - loss: 0.0154 - accuracy: 0.9338 - val_loss: 0.0158 - val_accuracy: 0.9299\nEpoch 6/10\n880/880 - 2s - loss: 0.0147 - accuracy: 0.9391 - val_loss: 0.0156 - val_accuracy: 0.9321\nEpoch 7/10\n880/880 - 2s - loss: 0.0143 - accuracy: 0.9419 - val_loss: 0.0152 - val_accuracy: 0.9351\nEpoch 8/10\n880/880 - 2s - loss: 0.0136 - accuracy: 0.9459 - val_loss: 0.0159 - val_accuracy: 0.9284\nEpoch 9/10\n880/880 - 2s - loss: 0.0136 - accuracy: 0.9462 - val_loss: 0.0154 - val_accuracy: 0.9333\nEpoch 10/10\n880/880 - 3s - loss: 0.0131 - accuracy: 0.9495 - val_loss: 0.0152 - val_accuracy: 0.9349\nEpoch 1/10\n880/880 - 2s - loss: 0.0300 - accuracy: 0.8593 - val_loss: 0.0206 - val_accuracy: 0.9095\nEpoch 2/10\n880/880 - 2s - loss: 0.0193 - accuracy: 0.9149 - val_loss: 0.0178 - val_accuracy: 0.9198\nEpoch 3/10\n880/880 - 2s - loss: 0.0171 - accuracy: 0.9237 - val_loss: 0.0178 - val_accuracy: 0.9198\nEpoch 4/10\n880/880 - 2s - loss: 0.0162 - accuracy: 0.9296 - val_loss: 0.0167 - val_accuracy: 0.9256\nEpoch 5/10\n880/880 - 2s - loss: 0.0154 - accuracy: 0.9344 - val_loss: 0.0171 - val_accuracy: 0.9219\nEpoch 6/10\n880/880 - 2s - loss: 0.0147 - accuracy: 0.9390 - val_loss: 0.0152 - val_accuracy: 0.9327\nEpoch 7/10\n880/880 - 2s - loss: 0.0143 - accuracy: 0.9413 - val_loss: 0.0157 - val_accuracy: 0.9303\nEpoch 8/10\n880/880 - 2s - loss: 0.0138 - accuracy: 0.9452 - val_loss: 0.0165 - val_accuracy: 0.9240\nEpoch 9/10\n880/880 - 2s - loss: 0.0133 - accuracy: 0.9474 - val_loss: 0.0152 - val_accuracy: 0.9329\nEpoch 10/10\n880/880 - 2s - loss: 0.0131 - accuracy: 0.9491 - val_loss: 0.0148 - val_accuracy: 0.9372\n","name":"stdout"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"<span style=\"color:#4527A0\"><h1 style=\"font-size:18px\">Trial complete</h1></span>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"<span style=\"color:#4527A0\"><h1 style=\"font-size:18px\">Trial summary</h1></span>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"<span style=\"color:cyan\"> |-Trial ID: 80ad7380444d10634525b5d7614d96cc</span>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"<span style=\"color:cyan\"> |-Score: 0.9361471831798553</span>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"<span style=\"color:cyan\"> |-Best step: 0</span>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"<span style=\"color:#7E57C2\"><h2 style=\"font-size:16px\">Hyperparameters:</h2></span>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"<span style=\"color:cyan\"> |-dense_activation: elu</span>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"<span style=\"color:blue\"> |-dropout: 0.05</span>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"<span style=\"color:cyan\"> |-learning_rate: 0.001</span>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"<span style=\"color:blue\"> |-units: 24</span>"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"# choosing best model among the models\nbest_model = tuner_rs.get_best_models(num_models=1)[0] \nloss, mse = best_model.evaluate(X_test,y_onehot_test)","execution_count":32,"outputs":[{"output_type":"stream","text":"434/434 [==============================] - ETA: 0s - loss: 0.0108 - accuracy: 0.96 - ETA: 0s - loss: 0.0129 - accuracy: 0.94 - ETA: 0s - loss: 0.0128 - accuracy: 0.94 - ETA: 0s - loss: 0.0133 - accuracy: 0.94 - ETA: 0s - loss: 0.0131 - accuracy: 0.94 - ETA: 0s - loss: 0.0133 - accuracy: 0.94 - ETA: 0s - loss: 0.0130 - accuracy: 0.94 - ETA: 0s - loss: 0.0128 - accuracy: 0.94 - ETA: 0s - loss: 0.0128 - accuracy: 0.94 - ETA: 0s - loss: 0.0128 - accuracy: 0.94 - ETA: 0s - loss: 0.0129 - accuracy: 0.94 - 1s 1ms/step - loss: 0.0129 - accuracy: 0.9417\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Shows layers of the model\nbest_model.layers","execution_count":33,"outputs":[{"output_type":"execute_result","execution_count":33,"data":{"text/plain":"[<tensorflow.python.keras.layers.core.Dense at 0x7effb24115d0>,\n <tensorflow.python.keras.layers.core.Dense at 0x7eff9acb7ed0>,\n <tensorflow.python.keras.layers.core.Dropout at 0x7eff9acb7110>,\n <tensorflow.python.keras.layers.core.Dense at 0x7eff9acaf490>]"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Shows weights of the model (w,b)\nbest_model.weights","execution_count":34,"outputs":[{"output_type":"execute_result","execution_count":34,"data":{"text/plain":"[<tf.Variable 'dense/kernel:0' shape=(784, 32) dtype=float32, numpy=\n array([[ 0.05674104, -0.01352786, -0.01758518, ..., -0.0708273 ,\n         -0.08358304,  0.06147327],\n        [ 0.0549344 , -0.02178866, -0.00855763, ...,  0.00630506,\n         -0.01228216, -0.07996556],\n        [-0.05019264,  0.03597376, -0.06447023, ...,  0.05501612,\n          0.01740073, -0.01145761],\n        ...,\n        [-0.04282255, -0.0755173 , -0.06505855, ..., -0.08535715,\n         -0.04575186,  0.05818256],\n        [-0.03975312,  0.02092221,  0.07825074, ...,  0.04816408,\n          0.01555977, -0.0218576 ],\n        [ 0.05946391,  0.02243678, -0.05928504, ..., -0.05080473,\n         -0.03221198,  0.06400909]], dtype=float32)>,\n <tf.Variable 'dense/bias:0' shape=(32,) dtype=float32, numpy=\n array([ 0.00173804,  0.0591086 , -0.0029832 ,  0.00903119,  0.10704599,\n         0.02942726, -0.00595056,  0.00302725,  0.0314567 , -0.00777636,\n         0.02910684, -0.00749242,  0.08771014, -0.01938568,  0.04341332,\n         0.05798694, -0.03001877, -0.04657395, -0.04111895,  0.03131244,\n         0.03563119,  0.09996685,  0.07113543,  0.10842636,  0.02687487,\n         0.05145857,  0.04428599, -0.03330641,  0.0032995 ,  0.04551385,\n         0.04373966, -0.00610822], dtype=float32)>,\n <tf.Variable 'dense_1/kernel:0' shape=(32, 32) dtype=float32, numpy=\n array([[-0.08307773, -0.04684832, -0.14692906, ..., -0.167451  ,\n         -0.02588665,  0.2379866 ],\n        [-0.22670443,  0.20705791,  0.06699845, ...,  0.28023377,\n          0.3177792 , -0.12022424],\n        [ 0.13546313,  0.26793715,  0.12526073, ...,  0.41327673,\n         -0.01806529, -0.2702163 ],\n        ...,\n        [ 0.0926623 ,  0.50388813,  0.50954545, ..., -0.07912192,\n          0.11807317,  0.16091914],\n        [-0.38598505,  0.10549384, -0.2451365 , ...,  0.0424921 ,\n          0.6299634 ,  0.49499178],\n        [ 0.07696611, -0.04934916, -0.23717545, ..., -0.16601534,\n          0.19885212,  0.28617358]], dtype=float32)>,\n <tf.Variable 'dense_1/bias:0' shape=(32,) dtype=float32, numpy=\n array([ 0.12230791,  0.1389783 ,  0.13924032,  0.2846968 ,  0.1365008 ,\n         0.0683602 ,  0.1728871 ,  0.24997483,  0.01223798,  0.13396688,\n         0.11736851, -0.01238151,  0.12758486,  0.16557057,  0.08878326,\n         0.13169576,  0.19039783,  0.1263325 ,  0.07863657,  0.09282953,\n         0.14627731,  0.22668871,  0.23221114,  0.17449911,  0.19248445,\n         0.23374403,  0.19832912,  0.12343251,  0.27193072,  0.01913127,\n         0.2779666 ,  0.13575971], dtype=float32)>,\n <tf.Variable 'dense_2/kernel:0' shape=(32, 10) dtype=float32, numpy=\n array([[ 4.43368971e-01, -4.71108884e-01,  3.74935687e-01,\n         -2.37859085e-01, -5.22081391e-05, -1.38530150e-01,\n         -4.37534362e-01,  3.55768085e-01, -1.43913835e-01,\n          4.48603332e-01],\n        [ 1.35058582e-01,  3.29855531e-01, -6.22398615e-01,\n         -4.60156888e-01,  4.47514683e-01,  6.17678642e-01,\n          5.69446027e-01,  3.20936173e-01,  2.08063245e-01,\n          1.17972130e-02],\n        [ 2.80672848e-01, -1.59852415e-01, -6.29416943e-01,\n         -2.80052722e-01,  4.06397879e-01, -3.16589810e-02,\n          4.28225666e-01,  5.43166772e-02, -8.47786814e-02,\n          3.45634073e-01],\n        [-6.82165146e-01, -6.20896459e-01, -6.34272158e-01,\n          2.18561795e-02,  1.19299963e-02,  5.12758434e-01,\n         -5.57046175e-01,  1.81825086e-01,  3.09376806e-01,\n          1.97639205e-02],\n        [-6.08601093e-01,  4.19066310e-01,  2.44971812e-01,\n          5.03483593e-01, -3.87540787e-01, -5.84113359e-01,\n          5.00627518e-01, -6.92503393e-01, -2.32073337e-01,\n          2.04334468e-01],\n        [ 5.74174345e-01, -1.13879330e-01, -3.58972758e-01,\n          1.17216371e-01, -3.78056407e-01, -4.60954532e-02,\n         -2.43821234e-01,  3.79014015e-01, -3.52206796e-01,\n          2.86855370e-01],\n        [-8.30930531e-01, -1.80021167e-01, -4.52720642e-01,\n         -5.73550999e-01,  5.97837687e-01, -6.13821685e-01,\n         -5.47860265e-01, -3.92462015e-01,  2.24456191e-01,\n          1.32360786e-01],\n        [-2.75323033e-01, -4.74460810e-01, -2.98135400e-01,\n          4.92405951e-01, -6.97676897e-01,  2.22935289e-01,\n          3.52968693e-01, -6.38042390e-01,  4.59956527e-01,\n         -9.83069614e-02],\n        [-2.88053721e-01, -1.54709399e-01,  6.42263144e-02,\n         -4.47735190e-01, -6.01250112e-01, -2.31671363e-01,\n         -5.35989285e-01,  6.21707797e-01, -1.32938579e-01,\n         -2.80550003e-01],\n        [ 5.90046167e-01,  4.33247834e-01,  4.71159846e-01,\n         -1.19036831e-01, -5.55605471e-01, -3.41128588e-01,\n         -9.88461003e-02, -6.93287477e-02, -3.40687245e-01,\n         -3.46070707e-01],\n        [-6.67504489e-01,  3.84709924e-01, -4.31441724e-01,\n         -4.68034744e-01, -5.98090410e-01,  3.95161361e-01,\n         -3.95640552e-01,  5.29100001e-01, -5.39077044e-01,\n          1.71007618e-01],\n        [ 2.24761292e-03,  2.87669897e-02, -1.28082886e-01,\n          4.63577034e-03, -1.46845564e-01, -2.18772329e-02,\n         -9.10244659e-02,  2.22776830e-01,  1.68137118e-01,\n          2.45157555e-01],\n        [-6.29535735e-01, -8.70350152e-02, -4.62138206e-01,\n          6.24027029e-02,  4.77000028e-01, -5.12615323e-01,\n         -4.43030208e-01,  2.40396380e-01, -1.14396550e-01,\n          6.67737871e-02],\n        [ 5.95997572e-01, -2.30963275e-01, -1.74322188e-01,\n         -2.29387715e-01, -6.42176926e-01, -1.96516141e-01,\n         -4.88319248e-01,  3.04921836e-01, -2.79038936e-01,\n          1.25633284e-01],\n        [-2.11534366e-01,  4.98677880e-01,  2.84403395e-02,\n         -2.08478287e-01, -4.42766249e-01, -3.68471622e-01,\n         -5.56706369e-01, -6.97390288e-02,  4.71962243e-01,\n          2.07187846e-01],\n        [-1.99365392e-01,  4.88077343e-01, -4.00072485e-01,\n          4.10047352e-01, -4.40715179e-02, -1.37223542e-01,\n         -1.27980843e-01,  5.00893295e-02,  6.09928370e-01,\n         -6.97326303e-01],\n        [ 2.55634874e-01, -4.03108835e-01,  4.11928818e-02,\n          4.48903263e-01,  2.93973684e-01, -2.36717924e-01,\n         -5.83354771e-01,  1.06081605e-01, -2.94816732e-01,\n         -6.85720146e-01],\n        [ 5.72642505e-01, -4.43862945e-01, -3.81767124e-01,\n         -1.19953670e-01, -1.61379248e-01, -1.09337583e-01,\n         -1.99989289e-01,  6.74678460e-02, -3.98034781e-01,\n          5.33654809e-01],\n        [ 2.46210117e-02,  4.15767461e-01,  4.62046504e-01,\n          1.33613482e-01, -1.13385111e-01, -6.68953717e-01,\n         -9.04508606e-02, -3.80346209e-01, -4.03957933e-01,\n          3.75636667e-01],\n        [-5.51571548e-01, -4.83340591e-01,  5.92209771e-03,\n          2.08442852e-01, -8.37546363e-02, -1.11692637e-01,\n          4.84852672e-01,  7.98104480e-02,  2.36766353e-01,\n          2.48237714e-01],\n        [ 2.64965832e-01,  2.63408095e-01, -7.17630446e-01,\n         -6.57233417e-01,  2.17102960e-01,  2.96879530e-01,\n         -5.98565161e-01,  2.63609469e-01, -1.16997004e-01,\n          3.43861967e-01],\n        [-5.11992335e-01, -4.86618817e-01,  1.37250006e-01,\n         -3.44406724e-01, -6.65498734e-01,  6.93602681e-01,\n         -1.27921090e-01, -2.79280692e-01,  1.23999566e-01,\n         -5.00563502e-01],\n        [ 4.72505271e-01, -2.35096127e-01,  1.06865913e-01,\n          4.54573601e-01,  3.83786261e-01,  3.54972810e-01,\n         -7.03272879e-01, -6.39622007e-03,  3.37634325e-01,\n         -1.56630188e-01],\n        [-7.12497294e-01,  1.08038887e-01,  1.32608786e-01,\n          2.31929898e-01, -3.62964243e-01, -3.50616723e-01,\n          4.90282364e-02,  2.19092265e-01, -4.06395674e-01,\n         -7.07666039e-01],\n        [-2.10602462e-01, -4.69968736e-01,  3.07828099e-01,\n          4.77817953e-02, -4.70805109e-01, -2.98873484e-02,\n         -5.93434215e-01, -4.83576655e-01,  5.03952324e-01,\n         -5.95587015e-01],\n        [ 4.44512427e-01, -1.35372013e-01,  2.79674709e-01,\n         -7.87336826e-01,  2.45858833e-01, -3.33731592e-01,\n          5.28871477e-01, -7.79437900e-01,  1.69521749e-01,\n         -1.11665688e-01],\n        [-1.65131643e-01,  1.53450996e-01,  5.58465302e-01,\n          4.82305318e-01, -6.20494843e-01, -9.88035202e-02,\n         -6.60122752e-01,  1.96331695e-01, -5.55248499e-01,\n         -4.18607771e-01],\n        [-7.79280066e-01, -2.66397864e-01,  4.93119985e-01,\n         -2.03296781e-01,  9.10913348e-02, -6.65516376e-01,\n         -1.30397201e-01,  4.92381342e-02, -4.78124648e-01,\n          3.17788005e-01],\n        [ 1.79682449e-01, -6.12006426e-01,  3.90263557e-01,\n         -5.67728698e-01,  2.97649074e-02,  2.44704872e-01,\n          4.58911091e-01, -4.89830017e-01, -3.89684260e-01,\n         -5.50387740e-01],\n        [-3.60025585e-01,  2.86197096e-01, -9.24005359e-02,\n         -7.07730174e-01,  1.83142424e-01, -4.19039726e-01,\n         -5.89293242e-02, -1.97537273e-01,  4.94566143e-01,\n          2.90956229e-01],\n        [-5.50453722e-01,  1.64579332e-01, -4.90095645e-01,\n          6.06722772e-01, -6.09643497e-02,  2.71226615e-01,\n         -5.95360577e-01, -6.73826337e-01, -9.18224454e-02,\n         -4.66929913e-01],\n        [-7.73542821e-02, -1.88523054e-01, -9.94851589e-02,\n          2.50366896e-01, -4.91197079e-01,  3.45768005e-01,\n          4.02856827e-01,  2.68786788e-01,  2.38581672e-01,\n         -1.15341231e-01]], dtype=float32)>,\n <tf.Variable 'dense_2/bias:0' shape=(10,) dtype=float32, numpy=\n array([ 0.05641548, -0.11991311,  0.04027973,  0.06927014,  0.12807392,\n         0.21198602,  0.05439707, -0.12103726, -0.1033201 , -0.11895733],\n       dtype=float32)>]"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"# used to see the content of the model. It gives a summary of the model.\n# here is the total number of parameters entering the nodes in each layer, which is called params. \n# There is 784 inputs in the first layer,that is, 784 w and 2 b and since there are 2 nodes, the total parameter entered into the nodes = 2 * 784 +2 = 1570\nbest_model.summary()\n","execution_count":35,"outputs":[{"output_type":"stream","text":"Model: \"sequential\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\ndense (Dense)                (None, 32)                25120     \n_________________________________________________________________\ndense_1 (Dense)              (None, 32)                1056      \n_________________________________________________________________\ndropout (Dropout)            (None, 32)                0         \n_________________________________________________________________\ndense_2 (Dense)              (None, 10)                330       \n=================================================================\nTotal params: 26,506\nTrainable params: 26,506\nNon-trainable params: 0\n_________________________________________________________________\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"# model fitting\nbest_model.fit(X_train, y_onehot_train,\n          batch_size=100, epochs=10)   # epochs = number of iterations","execution_count":36,"outputs":[{"output_type":"stream","text":"Epoch 1/10\n282/282 [==============================] - ETA: 0s - loss: 0.0076 - accuracy: 0.98 - ETA: 0s - loss: 0.0111 - accuracy: 0.95 - ETA: 0s - loss: 0.0115 - accuracy: 0.95 - ETA: 0s - loss: 0.0118 - accuracy: 0.95 - ETA: 0s - loss: 0.0119 - accuracy: 0.95 - ETA: 0s - loss: 0.0116 - accuracy: 0.95 - ETA: 0s - loss: 0.0116 - accuracy: 0.95 - ETA: 0s - loss: 0.0117 - accuracy: 0.95 - ETA: 0s - loss: 0.0117 - accuracy: 0.95 - ETA: 0s - loss: 0.0116 - accuracy: 0.95 - ETA: 0s - loss: 0.0116 - accuracy: 0.95 - ETA: 0s - loss: 0.0115 - accuracy: 0.95 - ETA: 0s - loss: 0.0114 - accuracy: 0.95 - 1s 2ms/step - loss: 0.0114 - accuracy: 0.9547\nEpoch 2/10\n282/282 [==============================] - ETA: 0s - loss: 0.0111 - accuracy: 0.96 - ETA: 0s - loss: 0.0106 - accuracy: 0.95 - ETA: 0s - loss: 0.0114 - accuracy: 0.95 - ETA: 0s - loss: 0.0114 - accuracy: 0.95 - ETA: 0s - loss: 0.0112 - accuracy: 0.95 - ETA: 0s - loss: 0.0111 - accuracy: 0.95 - ETA: 0s - loss: 0.0111 - accuracy: 0.95 - ETA: 0s - loss: 0.0111 - accuracy: 0.95 - ETA: 0s - loss: 0.0112 - accuracy: 0.95 - ETA: 0s - loss: 0.0111 - accuracy: 0.95 - ETA: 0s - loss: 0.0112 - accuracy: 0.95 - ETA: 0s - loss: 0.0112 - accuracy: 0.95 - ETA: 0s - loss: 0.0112 - accuracy: 0.95 - 1s 2ms/step - loss: 0.0112 - accuracy: 0.9553\nEpoch 3/10\n282/282 [==============================] - ETA: 0s - loss: 0.0123 - accuracy: 0.91 - ETA: 0s - loss: 0.0108 - accuracy: 0.95 - ETA: 0s - loss: 0.0107 - accuracy: 0.95 - ETA: 0s - loss: 0.0109 - accuracy: 0.95 - ETA: 0s - loss: 0.0109 - accuracy: 0.95 - ETA: 0s - loss: 0.0109 - accuracy: 0.95 - ETA: 0s - loss: 0.0108 - accuracy: 0.95 - ETA: 0s - loss: 0.0109 - accuracy: 0.95 - ETA: 0s - loss: 0.0109 - accuracy: 0.95 - ETA: 0s - loss: 0.0109 - accuracy: 0.95 - ETA: 0s - loss: 0.0109 - accuracy: 0.95 - ETA: 0s - loss: 0.0109 - accuracy: 0.95 - 1s 2ms/step - loss: 0.0109 - accuracy: 0.9569\nEpoch 4/10\n282/282 [==============================] - ETA: 0s - loss: 0.0126 - accuracy: 0.96 - ETA: 0s - loss: 0.0108 - accuracy: 0.95 - ETA: 0s - loss: 0.0111 - accuracy: 0.95 - ETA: 0s - loss: 0.0108 - accuracy: 0.95 - ETA: 0s - loss: 0.0108 - accuracy: 0.95 - ETA: 0s - loss: 0.0107 - accuracy: 0.95 - ETA: 0s - loss: 0.0108 - accuracy: 0.95 - ETA: 0s - loss: 0.0108 - accuracy: 0.95 - ETA: 0s - loss: 0.0108 - accuracy: 0.95 - ETA: 0s - loss: 0.0108 - accuracy: 0.95 - ETA: 0s - loss: 0.0108 - accuracy: 0.95 - ETA: 0s - loss: 0.0107 - accuracy: 0.95 - 1s 2ms/step - loss: 0.0106 - accuracy: 0.9585\nEpoch 5/10\n282/282 [==============================] - ETA: 0s - loss: 0.0111 - accuracy: 0.95 - ETA: 0s - loss: 0.0101 - accuracy: 0.96 - ETA: 0s - loss: 0.0097 - accuracy: 0.96 - ETA: 0s - loss: 0.0099 - accuracy: 0.96 - ETA: 0s - loss: 0.0101 - accuracy: 0.96 - ETA: 0s - loss: 0.0102 - accuracy: 0.95 - ETA: 0s - loss: 0.0101 - accuracy: 0.96 - ETA: 0s - loss: 0.0102 - accuracy: 0.96 - ETA: 0s - loss: 0.0102 - accuracy: 0.96 - ETA: 0s - loss: 0.0102 - accuracy: 0.95 - ETA: 0s - loss: 0.0103 - accuracy: 0.95 - ETA: 0s - loss: 0.0103 - accuracy: 0.95 - ETA: 0s - loss: 0.0104 - accuracy: 0.95 - 1s 2ms/step - loss: 0.0104 - accuracy: 0.9590\nEpoch 6/10\n282/282 [==============================] - ETA: 0s - loss: 0.0118 - accuracy: 0.94 - ETA: 0s - loss: 0.0094 - accuracy: 0.96 - ETA: 0s - loss: 0.0101 - accuracy: 0.96 - ETA: 0s - loss: 0.0101 - accuracy: 0.96 - ETA: 0s - loss: 0.0101 - accuracy: 0.96 - ETA: 0s - loss: 0.0101 - accuracy: 0.96 - ETA: 0s - loss: 0.0102 - accuracy: 0.96 - ETA: 0s - loss: 0.0101 - accuracy: 0.95 - ETA: 0s - loss: 0.0101 - accuracy: 0.95 - ETA: 0s - loss: 0.0101 - accuracy: 0.96 - ETA: 0s - loss: 0.0101 - accuracy: 0.96 - ETA: 0s - loss: 0.0101 - accuracy: 0.96 - 1s 2ms/step - loss: 0.0101 - accuracy: 0.9597\nEpoch 7/10\n282/282 [==============================] - ETA: 0s - loss: 0.0109 - accuracy: 0.96 - ETA: 0s - loss: 0.0098 - accuracy: 0.96 - ETA: 0s - loss: 0.0099 - accuracy: 0.96 - ETA: 0s - loss: 0.0099 - accuracy: 0.96 - ETA: 0s - loss: 0.0099 - accuracy: 0.96 - ETA: 0s - loss: 0.0099 - accuracy: 0.96 - ETA: 0s - loss: 0.0099 - accuracy: 0.96 - ETA: 0s - loss: 0.0098 - accuracy: 0.96 - ETA: 0s - loss: 0.0099 - accuracy: 0.96 - ETA: 0s - loss: 0.0099 - accuracy: 0.96 - ETA: 0s - loss: 0.0099 - accuracy: 0.96 - ETA: 0s - loss: 0.0099 - accuracy: 0.96 - ETA: 0s - loss: 0.0099 - accuracy: 0.96 - 1s 2ms/step - loss: 0.0099 - accuracy: 0.9609\nEpoch 8/10\n282/282 [==============================] - ETA: 0s - loss: 0.0078 - accuracy: 0.97 - ETA: 0s - loss: 0.0098 - accuracy: 0.96 - ETA: 0s - loss: 0.0100 - accuracy: 0.95 - ETA: 0s - loss: 0.0097 - accuracy: 0.96 - ETA: 0s - loss: 0.0096 - accuracy: 0.96 - ETA: 0s - loss: 0.0097 - accuracy: 0.96 - ETA: 0s - loss: 0.0096 - accuracy: 0.96 - ETA: 0s - loss: 0.0096 - accuracy: 0.96 - ETA: 0s - loss: 0.0096 - accuracy: 0.96 - ETA: 0s - loss: 0.0096 - accuracy: 0.96 - ETA: 0s - loss: 0.0096 - accuracy: 0.96 - ETA: 0s - loss: 0.0096 - accuracy: 0.96 - ETA: 0s - loss: 0.0096 - accuracy: 0.96 - 1s 2ms/step - loss: 0.0096 - accuracy: 0.9620\nEpoch 9/10\n282/282 [==============================] - ETA: 0s - loss: 0.0101 - accuracy: 0.97 - ETA: 0s - loss: 0.0093 - accuracy: 0.96 - ETA: 0s - loss: 0.0092 - accuracy: 0.96 - ETA: 0s - loss: 0.0091 - accuracy: 0.96 - ETA: 0s - loss: 0.0093 - accuracy: 0.96 - ETA: 0s - loss: 0.0092 - accuracy: 0.96 - ETA: 0s - loss: 0.0094 - accuracy: 0.96 - ETA: 0s - loss: 0.0094 - accuracy: 0.96 - ETA: 0s - loss: 0.0095 - accuracy: 0.96 - ETA: 0s - loss: 0.0094 - accuracy: 0.96 - ETA: 0s - loss: 0.0094 - accuracy: 0.96 - ETA: 0s - loss: 0.0094 - accuracy: 0.96 - ETA: 0s - loss: 0.0093 - accuracy: 0.96 - 1s 2ms/step - loss: 0.0094 - accuracy: 0.9636\nEpoch 10/10\n282/282 [==============================] - ETA: 0s - loss: 0.0109 - accuracy: 0.95 - ETA: 0s - loss: 0.0086 - accuracy: 0.96 - ETA: 0s - loss: 0.0087 - accuracy: 0.96 - ETA: 0s - loss: 0.0090 - accuracy: 0.96 - ETA: 0s - loss: 0.0091 - accuracy: 0.96 - ETA: 0s - loss: 0.0091 - accuracy: 0.96 - ETA: 0s - loss: 0.0091 - accuracy: 0.96 - ETA: 0s - loss: 0.0092 - accuracy: 0.96 - ETA: 0s - loss: 0.0091 - accuracy: 0.96 - ETA: 0s - loss: 0.0091 - accuracy: 0.96 - ETA: 0s - loss: 0.0091 - accuracy: 0.96 - ETA: 0s - loss: 0.0091 - accuracy: 0.96 - ETA: 0s - loss: 0.0091 - accuracy: 0.96 - 1s 2ms/step - loss: 0.0091 - accuracy: 0.9640\n","name":"stdout"},{"output_type":"execute_result","execution_count":36,"data":{"text/plain":"<tensorflow.python.keras.callbacks.History at 0x7effa0f28850>"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Model evaluation\ntest_loss, test_acc = best_model.evaluate(X_test, y_onehot_test)\nprint(\"Dev set accuracy: \", test_acc)\nprint(\"Dev set loss: \", test_loss)","execution_count":37,"outputs":[{"output_type":"stream","text":"434/434 [==============================] - ETA: 0s - loss: 0.0080 - accuracy: 0.96 - ETA: 0s - loss: 0.0108 - accuracy: 0.95 - ETA: 0s - loss: 0.0109 - accuracy: 0.94 - ETA: 0s - loss: 0.0112 - accuracy: 0.94 - ETA: 0s - loss: 0.0111 - accuracy: 0.94 - ETA: 0s - loss: 0.0113 - accuracy: 0.94 - ETA: 0s - loss: 0.0110 - accuracy: 0.94 - ETA: 0s - loss: 0.0109 - accuracy: 0.95 - ETA: 0s - loss: 0.0108 - accuracy: 0.95 - ETA: 0s - loss: 0.0108 - accuracy: 0.95 - ETA: 0s - loss: 0.0109 - accuracy: 0.95 - ETA: 0s - loss: 0.0109 - accuracy: 0.94 - 1s 1ms/step - loss: 0.0109 - accuracy: 0.9497\nDev set accuracy:  0.9497113823890686\nDev set loss:  0.010879306122660637\n","name":"stdout"}]},{"metadata":{},"cell_type":"markdown","source":"## Confusion Matrix\n\n\"\" In the field of machine learning and specifically the problem of statistical classification, a confusion matrix, also known as an error matrix, is a specific table layout that allows visualization of the performance of an algorithm, typically a supervised learning one. \"\""},{"metadata":{"trusted":true},"cell_type":"code","source":"# Plot confusion matrix \n# Note: This code snippet for confusion-matrix is taken directly from the SKLEARN website.\ndef plot_confusion_matrix(cm, classes,\n                          normalize=False,\n                          title='Confusion matrix',\n                          cmap=plt.cm.Blues):\n    \"\"\"\n    This function prints and plots the confusion matrix.\n    Normalization can be applied by setting `normalize=True`.\n    \"\"\"\n    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n    plt.title(title)\n    plt.colorbar()\n    tick_marks = np.arange(len(classes))\n    plt.xticks(tick_marks, classes, rotation=30)\n    plt.yticks(tick_marks, classes)\n\n    if normalize:\n        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n\n    thresh = cm.max() / 2.\n    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n        plt.text(j, i, cm[i, j],\n                 horizontalalignment=\"center\",\n                 color=\"white\" if cm[i, j] > thresh else \"black\")\n\n    plt.tight_layout()\n    plt.ylabel('Actual class')\n    plt.xlabel('Predicted class')","execution_count":38,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from collections import Counter\nfrom sklearn.metrics import confusion_matrix\nimport itertools\n\n# Predict the values from the validation dataset\nY_pred = best_model.predict(X_test)\n# Convert predictions classes to one hot vectors \nY_pred_classes = np.argmax(Y_pred, axis = 1) \n# Convert validation observations to one hot vectors\nY_true = np.argmax(y_onehot_test, axis = 1) \n# compute the confusion matrix\nconfusion_mtx = confusion_matrix(Y_true, Y_pred_classes) \n# plot the confusion matrix\nplot_confusion_matrix(confusion_mtx, classes = range(10))","execution_count":39,"outputs":[{"output_type":"display_data","data":{"text/plain":"<Figure size 432x288 with 2 Axes>","image/png":"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\n"},"metadata":{"needs_background":"light"}}]},{"metadata":{},"cell_type":"markdown","source":"# Prediction dev-set"},{"metadata":{"trusted":true},"cell_type":"code","source":"# The Predict () method returns a vector containing the predictions of all dataset items.\npredictions = best_model.predict(X_test)","execution_count":40,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Returning the index of the position containing the highest value of the vector, we know which class gives the highest probability of belonging with the argmax function of Numpy.\nnp.argmax(predictions[9])","execution_count":41,"outputs":[{"output_type":"execute_result","execution_count":41,"data":{"text/plain":"1"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"# We can use sum to see that all values â€‹â€‹in a vector are zero. Because these are probability values.\nnp.sum(predictions[11])","execution_count":42,"outputs":[{"output_type":"execute_result","execution_count":42,"data":{"text/plain":"1.0000001"},"metadata":{}}]},{"metadata":{},"cell_type":"markdown","source":"# Prediction test-set"},{"metadata":{"trusted":true},"cell_type":"code","source":"# The Predict () method returns a vector containing the predictions of all dataset items.\ntest_result = best_model.predict(test)","execution_count":43,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Write results to csv "},{"metadata":{"trusted":true},"cell_type":"code","source":"# Saving the results to a csv file\n\n# Convert one-hot vector to number\nresults = np.argmax(test_result,axis = 1) # this gives us the corresponding y value relative to the highest probability in the prediction vector, such as 2 or 3\n\nresults = pd.Series(results,name=\"Label\")\n\n\nsubmission = pd.concat([pd.Series(range(1,28001),name = \"ImageId\"),results],axis = 1)\n\nsubmission.to_csv(\"test_submission.csv\",index=False)","execution_count":44,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"markdown","source":"## I AM LOOKING FORWARD TO YOUR COMMENTS AND UPVOTES \n\n## If you have any questiÌ‡on, please donot hesiÌ‡tate to ask.\n\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.7.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":4}